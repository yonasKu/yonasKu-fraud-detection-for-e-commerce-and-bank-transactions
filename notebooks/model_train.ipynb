{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\myvenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('../fraud_detection')  # Adjust this path based on your working directory\n",
    "from utils.logging_util import setup_logger\n",
    "\n",
    "# notebooks/eda_fraud_detection.ipynb\n",
    "\n",
    "# Import the necessary functions from your project\n",
    "# from model_training import prepare_data, train_logistic_regression , train_random_forest , train_gradient_boosting ,train_decision_tree,  train_mlp,train_rnn,train_cnn,train_lstm\n",
    "from model_training import (prepare_data, prepare_credit_card_data,train_logistic_regression, train_random_forest, \n",
    "                            train_gradient_boosting, train_decision_tree,prepare_large_data )\n",
    "\n",
    "from model_evaluation import evaluate_model\n",
    "\n",
    "from model_explainability import explain_model_shap, explain_model_lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '../data/fraud_datas.csv'\n",
    "# prepared_data = prepare_data(data_path, target_column='fraud_class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:19:23,439 - INFO - Loaded data from ../data/credit_datas.csv\n",
      "2024-11-25 20:19:23,439 - model_training - INFO - Loaded data from ../data/credit_datas.csv\n",
      "2024-11-25 20:19:23,439 - model_training - INFO - Loaded data from ../data/credit_datas.csv\n",
      "2024-11-25 20:19:23,439 - model_training - INFO - Loaded data from ../data/credit_datas.csv\n",
      "2024-11-25 20:19:23,968 - INFO - Data successfully split into training and testing sets.\n",
      "2024-11-25 20:19:23,968 - model_training - INFO - Data successfully split into training and testing sets.\n",
      "2024-11-25 20:19:23,968 - model_training - INFO - Data successfully split into training and testing sets.\n",
      "2024-11-25 20:19:23,968 - model_training - INFO - Data successfully split into training and testing sets.\n",
      "2024-11-25 20:19:24,301 - INFO - Feature scaling applied.\n",
      "2024-11-25 20:19:24,301 - model_training - INFO - Feature scaling applied.\n",
      "2024-11-25 20:19:24,301 - model_training - INFO - Feature scaling applied.\n",
      "2024-11-25 20:19:24,301 - model_training - INFO - Feature scaling applied.\n"
     ]
    }
   ],
   "source": [
    "# Path to the credit card dataset\n",
    "data_path = \"../data/credit_datas.csv\"\n",
    "target_column = \"Class\"  # Target column indicating fraud (1 = Fraud, 0 = Non-Fraud)\n",
    "\n",
    "# Prepare the data for credit card fraud detection\n",
    "credit_data = prepare_credit_card_data(data_path, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:19:25,671 - INFO - Loaded data from ../data/Fraudlent_Datas.csv\n",
      "2024-11-25 20:19:25,671 - model_training - INFO - Loaded data from ../data/Fraudlent_Datas.csv\n",
      "2024-11-25 20:19:25,671 - model_training - INFO - Loaded data from ../data/Fraudlent_Datas.csv\n",
      "2024-11-25 20:19:25,671 - model_training - INFO - Loaded data from ../data/Fraudlent_Datas.csv\n",
      "2024-11-25 20:19:26,624 - INFO - Calculated 'time_to_purchase' and dropped 'signup_time' and 'purchase_time'.\n",
      "2024-11-25 20:19:26,624 - model_training - INFO - Calculated 'time_to_purchase' and dropped 'signup_time' and 'purchase_time'.\n",
      "2024-11-25 20:19:26,624 - model_training - INFO - Calculated 'time_to_purchase' and dropped 'signup_time' and 'purchase_time'.\n",
      "2024-11-25 20:19:26,624 - model_training - INFO - Calculated 'time_to_purchase' and dropped 'signup_time' and 'purchase_time'.\n",
      "2024-11-25 20:19:26,733 - INFO - Encoded 'country' using frequency encoding.\n",
      "2024-11-25 20:19:26,733 - model_training - INFO - Encoded 'country' using frequency encoding.\n",
      "2024-11-25 20:19:26,733 - model_training - INFO - Encoded 'country' using frequency encoding.\n",
      "2024-11-25 20:19:26,733 - model_training - INFO - Encoded 'country' using frequency encoding.\n",
      "2024-11-25 20:19:26,872 - INFO - Encoded column: source using one-hot encoding.\n",
      "2024-11-25 20:19:26,872 - model_training - INFO - Encoded column: source using one-hot encoding.\n",
      "2024-11-25 20:19:26,872 - model_training - INFO - Encoded column: source using one-hot encoding.\n",
      "2024-11-25 20:19:26,872 - model_training - INFO - Encoded column: source using one-hot encoding.\n",
      "2024-11-25 20:19:26,969 - INFO - Encoded column: browser using one-hot encoding.\n",
      "2024-11-25 20:19:26,969 - model_training - INFO - Encoded column: browser using one-hot encoding.\n",
      "2024-11-25 20:19:26,969 - model_training - INFO - Encoded column: browser using one-hot encoding.\n",
      "2024-11-25 20:19:26,969 - model_training - INFO - Encoded column: browser using one-hot encoding.\n",
      "2024-11-25 20:19:27,058 - INFO - Encoded column: sex using one-hot encoding.\n",
      "2024-11-25 20:19:27,058 - model_training - INFO - Encoded column: sex using one-hot encoding.\n",
      "2024-11-25 20:19:27,058 - model_training - INFO - Encoded column: sex using one-hot encoding.\n",
      "2024-11-25 20:19:27,058 - model_training - INFO - Encoded column: sex using one-hot encoding.\n",
      "2024-11-25 20:19:27,090 - INFO - Dropped irrelevant columns: ['user_id', 'device_id', 'ip_address']\n",
      "2024-11-25 20:19:27,090 - model_training - INFO - Dropped irrelevant columns: ['user_id', 'device_id', 'ip_address']\n",
      "2024-11-25 20:19:27,090 - model_training - INFO - Dropped irrelevant columns: ['user_id', 'device_id', 'ip_address']\n",
      "2024-11-25 20:19:27,090 - model_training - INFO - Dropped irrelevant columns: ['user_id', 'device_id', 'ip_address']\n",
      "2024-11-25 20:19:27,115 - INFO - Features (X) and target (y) defined. Target column: class\n",
      "2024-11-25 20:19:27,115 - model_training - INFO - Features (X) and target (y) defined. Target column: class\n",
      "2024-11-25 20:19:27,115 - model_training - INFO - Features (X) and target (y) defined. Target column: class\n",
      "2024-11-25 20:19:27,115 - model_training - INFO - Features (X) and target (y) defined. Target column: class\n",
      "2024-11-25 20:19:27,185 - INFO - Data split into train and test sets with test size = 0.2.\n",
      "2024-11-25 20:19:27,185 - model_training - INFO - Data split into train and test sets with test size = 0.2.\n",
      "2024-11-25 20:19:27,185 - model_training - INFO - Data split into train and test sets with test size = 0.2.\n",
      "2024-11-25 20:19:27,185 - model_training - INFO - Data split into train and test sets with test size = 0.2.\n",
      "2024-11-25 20:19:27,452 - INFO - Standardized the data.\n",
      "2024-11-25 20:19:27,452 - model_training - INFO - Standardized the data.\n",
      "2024-11-25 20:19:27,452 - model_training - INFO - Standardized the data.\n",
      "2024-11-25 20:19:27,452 - model_training - INFO - Standardized the data.\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/Fraudlent_Datas.csv'\n",
    "prepared_data = prepare_large_data(data_path, target_column='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Accessing the training and testing sets for credit card fraud detection\n",
    "# X_train_credit = credit_data['X_train']\n",
    "# X_test_credit = credit_data['X_test']\n",
    "# y_train_credit = credit_data['y_train']\n",
    "# y_test_credit = credit_data['y_test']\n",
    "# scaler_credit = prepared_data.get('scaler')\n",
    "# # Display confirmation\n",
    "# print(\"Credit card fraud data successfully prepared.\")\n",
    "# print(f\"Training set size: {X_train_credit.shape[0]} samples\")\n",
    "# print(f\"Test set size: {X_test_credit.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Access the prepared data\n",
    "# X_train = prepared_data['X_train']\n",
    "# X_test = prepared_data['X_test']\n",
    "# y_train = prepared_data['y_train']\n",
    "# y_test = prepared_data['y_test']\n",
    "# scaler = prepared_data.get('scaler')\n",
    "\n",
    "# # Display confirmation\n",
    "# print(\"fraud data successfully prepared.\")\n",
    "# print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "# print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit card fraud data successfully prepared.\n",
      "Training set size: 103316 samples\n",
      "Test set size: 25830 samples\n",
      "Feature names in X_train (before scaling):\n",
      "['purchase_value', 'age', 'transaction_frequency', 'transaction_count', 'transaction_velocity', 'hour_of_day', 'day_of_week', 'time_to_purchase', 'country_encoded', 'source_Direct', 'source_SEO', 'browser_FireFox', 'browser_IE', 'browser_Opera', 'browser_Safari', 'sex_M']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Access the prepared data\n",
    "X_train = prepared_data['X_train']\n",
    "X_test = prepared_data['X_test']\n",
    "y_train = prepared_data['y_train']\n",
    "y_test = prepared_data['y_test']\n",
    "scaler = prepared_data.get('scaler')\n",
    "\n",
    "# Display confirmation\n",
    "print(\"Credit card fraud data successfully prepared.\")\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "feature_names = prepared_data['feature_names']\n",
    "print(\"Feature names in X_train (before scaling):\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:19:27,554 - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:19:27,554 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:19:27,554 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:19:27,554 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:19:27,854 - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-25 20:19:27,854 - model_training - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-25 20:19:27,854 - model_training - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-25 20:19:27,854 - model_training - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-25 20:19:27,867 - INFO - Scaler saved to ../models/logistic_regression_scaler.pkl.\n",
      "2024-11-25 20:19:27,867 - model_training - INFO - Scaler saved to ../models/logistic_regression_scaler.pkl.\n",
      "2024-11-25 20:19:27,867 - model_training - INFO - Scaler saved to ../models/logistic_regression_scaler.pkl.\n",
      "2024-11-25 20:19:27,867 - model_training - INFO - Scaler saved to ../models/logistic_regression_scaler.pkl.\n",
      "2024-11-25 20:19:27,974 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:19:27,974 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:19:27,974 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:19:27,974 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:19:27,985 - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:19:27,985 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:19:27,985 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:19:27,985 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:20:25,739 - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-25 20:20:25,739 - model_training - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-25 20:20:25,739 - model_training - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-25 20:20:25,739 - model_training - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-25 20:20:25,754 - INFO - Scaler saved to ../models/random_forest_scaler.pkl.\n",
      "2024-11-25 20:20:25,754 - model_training - INFO - Scaler saved to ../models/random_forest_scaler.pkl.\n",
      "2024-11-25 20:20:25,754 - model_training - INFO - Scaler saved to ../models/random_forest_scaler.pkl.\n",
      "2024-11-25 20:20:25,754 - model_training - INFO - Scaler saved to ../models/random_forest_scaler.pkl.\n",
      "2024-11-25 20:20:28,815 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:28,815 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:28,815 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:28,815 - model_training - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': LogisticRegression(class_weight='balanced', max_iter=2000), 'training_time': 0.28107404708862305, 'roc_auc': np.float64(0.7594477170742543), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.64      0.76     23389\\n           1       0.17      0.71      0.27      2441\\n\\n    accuracy                           0.64     25830\\n   macro avg       0.56      0.67      0.52     25830\\nweighted avg       0.88      0.64      0.72     25830\\n'}\n",
      "{'model': RandomForestClassifier(class_weight='balanced'), 'training_time': 57.49529266357422, 'roc_auc': np.float64(0.7720956722391218), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.98     23389\\n           1       1.00      0.55      0.71      2441\\n\\n    accuracy                           0.96     25830\\n   macro avg       0.98      0.77      0.84     25830\\nweighted avg       0.96      0.96      0.95     25830\\n'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and save the Logistic Regression model and its scaler\n",
    "logistic_model_path = '../models/logistic_regression_model.pkl'\n",
    "logistic_scaler_path = '../models/logistic_regression_scaler.pkl'\n",
    "logistic_results = train_logistic_regression(X_train, X_test, y_train, y_test, logistic_model_path, scaler, logistic_scaler_path)\n",
    "\n",
    "# Train and save the Random Forest model and its scaler\n",
    "random_forest_model_path = '../models/random_forest_model.pkl'\n",
    "random_forest_scaler_path = '../models/random_forest_scaler.pkl'\n",
    "random_forest_results = train_random_forest(X_train, X_test, y_train, y_test, random_forest_model_path, scaler, random_forest_scaler_path)\n",
    "\n",
    "# Display results\n",
    "print(logistic_results)\n",
    "print(random_forest_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:20:28,875 - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:20:28,875 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:20:28,875 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:20:28,875 - model_training - INFO - Training model: LogisticRegression.\n",
      "2024-11-25 20:20:31,181 - INFO - Model saved to ../models/credit_logistic_regression_model.pkl.\n",
      "2024-11-25 20:20:31,181 - model_training - INFO - Model saved to ../models/credit_logistic_regression_model.pkl.\n",
      "2024-11-25 20:20:31,181 - model_training - INFO - Model saved to ../models/credit_logistic_regression_model.pkl.\n",
      "2024-11-25 20:20:31,181 - model_training - INFO - Model saved to ../models/credit_logistic_regression_model.pkl.\n",
      "2024-11-25 20:20:31,196 - INFO - Scaler saved to ../models/credit_logistic_scaler.pkl.\n",
      "2024-11-25 20:20:31,196 - model_training - INFO - Scaler saved to ../models/credit_logistic_scaler.pkl.\n",
      "2024-11-25 20:20:31,196 - model_training - INFO - Scaler saved to ../models/credit_logistic_scaler.pkl.\n",
      "2024-11-25 20:20:31,196 - model_training - INFO - Scaler saved to ../models/credit_logistic_scaler.pkl.\n",
      "2024-11-25 20:20:31,325 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:31,325 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:31,325 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:31,325 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:20:31,332 - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:20:31,332 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:20:31,332 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:20:31,332 - model_training - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-25 20:26:09,576 - INFO - Model saved to ../models/credit_random_forest_model.pkl.\n",
      "2024-11-25 20:26:09,576 - model_training - INFO - Model saved to ../models/credit_random_forest_model.pkl.\n",
      "2024-11-25 20:26:09,576 - model_training - INFO - Model saved to ../models/credit_random_forest_model.pkl.\n",
      "2024-11-25 20:26:09,576 - model_training - INFO - Model saved to ../models/credit_random_forest_model.pkl.\n",
      "2024-11-25 20:26:09,588 - INFO - Scaler saved to ../models/credit_random_forest_scaler.pkl.\n",
      "2024-11-25 20:26:09,588 - model_training - INFO - Scaler saved to ../models/credit_random_forest_scaler.pkl.\n",
      "2024-11-25 20:26:09,588 - model_training - INFO - Scaler saved to ../models/credit_random_forest_scaler.pkl.\n",
      "2024-11-25 20:26:09,588 - model_training - INFO - Scaler saved to ../models/credit_random_forest_scaler.pkl.\n",
      "2024-11-25 20:26:11,578 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:11,578 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:11,578 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:11,578 - model_training - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results (Credit Card Fraud):\n",
      "{'model': LogisticRegression(class_weight='balanced', max_iter=2000), 'training_time': 2.2915356159210205, 'roc_auc': np.float64(0.9754564584706141), 'report': '              precision    recall  f1-score   support\\n\\n           0       1.00      0.98      0.99     56656\\n           1       0.06      0.89      0.11        90\\n\\n    accuracy                           0.98     56746\\n   macro avg       0.53      0.93      0.55     56746\\nweighted avg       1.00      0.98      0.99     56746\\n'}\n",
      "\n",
      "Random Forest Results (Credit Card Fraud):\n",
      "{'model': RandomForestClassifier(class_weight='balanced'), 'training_time': 338.11589002609253, 'roc_auc': np.float64(0.9369730380620666), 'report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00     56656\\n           1       0.98      0.71      0.83        90\\n\\n    accuracy                           1.00     56746\\n   macro avg       0.99      0.86      0.91     56746\\nweighted avg       1.00      1.00      1.00     56746\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Access the prepared credit card fraud data\n",
    "X_train_credit = credit_data['X_train']\n",
    "X_test_credit = credit_data['X_test']\n",
    "y_train_credit = credit_data['y_train']\n",
    "y_test_credit = credit_data['y_test']\n",
    "credit_scaler = credit_data.get('scaler')\n",
    "\n",
    "# Train and save the Logistic Regression model for credit card fraud detection\n",
    "credit_logistic_model_path = '../models/credit_logistic_regression_model.pkl'\n",
    "credit_logistic_scaler_path = '../models/credit_logistic_scaler.pkl'\n",
    "credit_logistic_results = train_logistic_regression(\n",
    "    X_train_credit, X_test_credit, y_train_credit, y_test_credit, \n",
    "    credit_logistic_model_path, credit_scaler, credit_logistic_scaler_path\n",
    ")\n",
    "\n",
    "# Train and save the Random Forest model for credit card fraud detection\n",
    "credit_random_forest_model_path = '../models/credit_random_forest_model.pkl'\n",
    "credit_random_forest_scaler_path = '../models/credit_random_forest_scaler.pkl'\n",
    "credit_random_forest_results = train_random_forest(\n",
    "    X_train_credit, X_test_credit, y_train_credit, y_test_credit, \n",
    "    credit_random_forest_model_path, credit_scaler, credit_random_forest_scaler_path\n",
    ")\n",
    "\n",
    "# Display results for credit card fraud detection models\n",
    "print(\"\\nLogistic Regression Results (Credit Card Fraud):\")\n",
    "print(credit_logistic_results)\n",
    "\n",
    "print(\"\\nRandom Forest Results (Credit Card Fraud):\")\n",
    "print(credit_random_forest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:26:11,615 - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:26:11,615 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:26:11,615 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:26:11,615 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:26:14,896 - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-25 20:26:14,896 - model_training - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-25 20:26:14,896 - model_training - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-25 20:26:14,896 - model_training - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-25 20:26:14,909 - INFO - Scaler saved to ../models/decision_tree_scaler.pkl.\n",
      "2024-11-25 20:26:14,909 - model_training - INFO - Scaler saved to ../models/decision_tree_scaler.pkl.\n",
      "2024-11-25 20:26:14,909 - model_training - INFO - Scaler saved to ../models/decision_tree_scaler.pkl.\n",
      "2024-11-25 20:26:14,909 - model_training - INFO - Scaler saved to ../models/decision_tree_scaler.pkl.\n",
      "2024-11-25 20:26:14,998 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:14,998 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:14,998 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:14,998 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:26:15,006 - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:26:15,006 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:26:15,006 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:26:15,006 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:27:04,919 - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-25 20:27:04,919 - model_training - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-25 20:27:04,919 - model_training - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-25 20:27:04,919 - model_training - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-25 20:27:04,932 - INFO - Scaler saved to ../models/gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:27:04,932 - model_training - INFO - Scaler saved to ../models/gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:27:04,932 - model_training - INFO - Scaler saved to ../models/gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:27:04,932 - model_training - INFO - Scaler saved to ../models/gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:27:05,102 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:27:05,102 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:27:05,102 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:27:05,102 - model_training - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Model Results:\n",
      "{'model': DecisionTreeClassifier(), 'training_time': 3.2705187797546387, 'roc_auc': np.float64(0.7564399340446334), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.94      0.95     23389\\n           1       0.49      0.58      0.53      2441\\n\\n    accuracy                           0.90     25830\\n   macro avg       0.72      0.76      0.74     25830\\nweighted avg       0.91      0.90      0.91     25830\\n'}\n",
      "\n",
      "Gradient Boosting Model Results:\n",
      "{'model': GradientBoostingClassifier(), 'training_time': 49.88558793067932, 'roc_auc': np.float64(0.7809695885184598), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.98     23389\\n           1       1.00      0.55      0.71      2441\\n\\n    accuracy                           0.96     25830\\n   macro avg       0.98      0.77      0.84     25830\\nweighted avg       0.96      0.96      0.95     25830\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Define paths for Decision Tree and Gradient Boosting models and scalers\n",
    "decision_tree_model_path = '../models/decision_tree_model.pkl'\n",
    "decision_tree_scaler_path = '../models/decision_tree_scaler.pkl'\n",
    "\n",
    "gradient_boosting_model_path = '../models/gradient_boosting_model.pkl'\n",
    "gradient_boosting_scaler_path = '../models/gradient_boosting_scaler.pkl'\n",
    "\n",
    "\n",
    "# Train and save the Decision Tree model and its scaler\n",
    "decision_tree_results = train_decision_tree(\n",
    "    X_train, X_test, y_train, y_test, decision_tree_model_path, scaler, decision_tree_scaler_path\n",
    ")\n",
    "\n",
    "# Train and save the Gradient Boosting model and its scaler\n",
    "gradient_boosting_results = train_gradient_boosting(\n",
    "    X_train, X_test, y_train, y_test, gradient_boosting_model_path, scaler, gradient_boosting_scaler_path\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDecision Tree Model Results:\")\n",
    "print(decision_tree_results)\n",
    "\n",
    "print(\"\\nGradient Boosting Model Results:\")\n",
    "print(gradient_boosting_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:27:05,137 - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:27:05,137 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:27:05,137 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:27:05,137 - model_training - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-25 20:28:13,743 - INFO - Model saved to ../models/credit_decision_tree_model.pkl.\n",
      "2024-11-25 20:28:13,743 - model_training - INFO - Model saved to ../models/credit_decision_tree_model.pkl.\n",
      "2024-11-25 20:28:13,743 - model_training - INFO - Model saved to ../models/credit_decision_tree_model.pkl.\n",
      "2024-11-25 20:28:13,743 - model_training - INFO - Model saved to ../models/credit_decision_tree_model.pkl.\n",
      "2024-11-25 20:28:13,756 - INFO - Scaler saved to ../models/credit_decision_tree_scaler.pkl.\n",
      "2024-11-25 20:28:13,756 - model_training - INFO - Scaler saved to ../models/credit_decision_tree_scaler.pkl.\n",
      "2024-11-25 20:28:13,756 - model_training - INFO - Scaler saved to ../models/credit_decision_tree_scaler.pkl.\n",
      "2024-11-25 20:28:13,756 - model_training - INFO - Scaler saved to ../models/credit_decision_tree_scaler.pkl.\n",
      "2024-11-25 20:28:13,898 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:28:13,898 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:28:13,898 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:28:13,898 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:28:13,908 - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:28:13,908 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:28:13,908 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:28:13,908 - model_training - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-25 20:45:05,299 - INFO - Model saved to ../models/credit_gradient_boosting_model.pkl.\n",
      "2024-11-25 20:45:05,299 - model_training - INFO - Model saved to ../models/credit_gradient_boosting_model.pkl.\n",
      "2024-11-25 20:45:05,299 - model_training - INFO - Model saved to ../models/credit_gradient_boosting_model.pkl.\n",
      "2024-11-25 20:45:05,299 - model_training - INFO - Model saved to ../models/credit_gradient_boosting_model.pkl.\n",
      "2024-11-25 20:45:05,315 - INFO - Scaler saved to ../models/credit_gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:45:05,315 - model_training - INFO - Scaler saved to ../models/credit_gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:45:05,315 - model_training - INFO - Scaler saved to ../models/credit_gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:45:05,315 - model_training - INFO - Scaler saved to ../models/credit_gradient_boosting_scaler.pkl.\n",
      "2024-11-25 20:45:05,720 - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:45:05,720 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:45:05,720 - model_training - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-25 20:45:05,720 - model_training - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Model Results (Credit Card Fraud):\n",
      "{'model': DecisionTreeClassifier(), 'training_time': 68.59244465827942, 'roc_auc': np.float64(0.8608640057736359), 'report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00     56656\\n           1       0.70      0.72      0.71        90\\n\\n    accuracy                           1.00     56746\\n   macro avg       0.85      0.86      0.85     56746\\nweighted avg       1.00      1.00      1.00     56746\\n'}\n",
      "\n",
      "Gradient Boosting Model Results (Credit Card Fraud):\n",
      "{'model': GradientBoostingClassifier(), 'training_time': 1011.3606970310211, 'roc_auc': np.float64(0.7665101666195988), 'report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00     56656\\n           1       0.90      0.63      0.75        90\\n\\n    accuracy                           1.00     56746\\n   macro avg       0.95      0.82      0.87     56746\\nweighted avg       1.00      1.00      1.00     56746\\n'}\n"
     ]
    }
   ],
   "source": [
    "credit_decision_tree_model_path = '../models/credit_decision_tree_model.pkl'\n",
    "credit_decision_tree_scaler_path = '../models/credit_decision_tree_scaler.pkl'\n",
    "\n",
    "credit_gradient_boosting_model_path = '../models/credit_gradient_boosting_model.pkl'\n",
    "credit_gradient_boosting_scaler_path = '../models/credit_gradient_boosting_scaler.pkl'\n",
    "\n",
    "\n",
    "# Train and save the Decision Tree model for credit card fraud detection\n",
    "credit_decision_tree_results = train_decision_tree(\n",
    "    X_train_credit, X_test_credit, y_train_credit, y_test_credit,\n",
    "    credit_decision_tree_model_path, credit_scaler, credit_decision_tree_scaler_path\n",
    ")\n",
    "\n",
    "# Train and save the Gradient Boosting model for credit card fraud detection\n",
    "credit_gradient_boosting_results = train_gradient_boosting(\n",
    "    X_train_credit, X_test_credit, y_train_credit, y_test_credit,\n",
    "    credit_gradient_boosting_model_path, credit_scaler, credit_gradient_boosting_scaler_path\n",
    ")\n",
    "\n",
    "# Display results for credit card fraud detection models\n",
    "print(\"\\nDecision Tree Model Results (Credit Card Fraud):\")\n",
    "print(credit_decision_tree_results)\n",
    "\n",
    "print(\"\\nGradient Boosting Model Results (Credit Card Fraud):\")\n",
    "print(credit_gradient_boosting_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:45:05,867 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:05,867 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:05,867 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:05,875 - root - INFO - Accuracy: 0.6443670150987224\n",
      "2024-11-25 20:45:05,875 - root - INFO - Accuracy: 0.6443670150987224\n",
      "2024-11-25 20:45:05,875 - root - INFO - Accuracy: 0.6443670150987224\n",
      "2024-11-25 20:45:05,884 - root - INFO - Precision: 0.16945996275605213\n",
      "2024-11-25 20:45:05,884 - root - INFO - Precision: 0.16945996275605213\n",
      "2024-11-25 20:45:05,884 - root - INFO - Precision: 0.16945996275605213\n",
      "2024-11-25 20:45:05,894 - root - INFO - Recall: 0.7083162638263008\n",
      "2024-11-25 20:45:05,894 - root - INFO - Recall: 0.7083162638263008\n",
      "2024-11-25 20:45:05,894 - root - INFO - Recall: 0.7083162638263008\n",
      "2024-11-25 20:45:05,903 - root - INFO - F1 Score: 0.27348940208794686\n",
      "2024-11-25 20:45:05,903 - root - INFO - F1 Score: 0.27348940208794686\n",
      "2024-11-25 20:45:05,903 - root - INFO - F1 Score: 0.27348940208794686\n",
      "2024-11-25 20:45:05,914 - root - INFO - ROC AUC: 0.7594477170742543\n",
      "2024-11-25 20:45:05,914 - root - INFO - ROC AUC: 0.7594477170742543\n",
      "2024-11-25 20:45:05,914 - root - INFO - ROC AUC: 0.7594477170742543\n",
      "2024-11-25 20:45:05,923 - root - INFO - Confusion Matrix: \n",
      "[[14915  8474]\n",
      " [  712  1729]]\n",
      "2024-11-25 20:45:05,923 - root - INFO - Confusion Matrix: \n",
      "[[14915  8474]\n",
      " [  712  1729]]\n",
      "2024-11-25 20:45:05,923 - root - INFO - Confusion Matrix: \n",
      "[[14915  8474]\n",
      " [  712  1729]]\n",
      "2024-11-25 20:45:06,054 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:06,054 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:06,054 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:06,060 - root - INFO - Accuracy: 0.9034456058846303\n",
      "2024-11-25 20:45:06,060 - root - INFO - Accuracy: 0.9034456058846303\n",
      "2024-11-25 20:45:06,060 - root - INFO - Accuracy: 0.9034456058846303\n",
      "2024-11-25 20:45:06,065 - root - INFO - Precision: 0.49073750436910174\n",
      "2024-11-25 20:45:06,065 - root - INFO - Precision: 0.49073750436910174\n",
      "2024-11-25 20:45:06,065 - root - INFO - Precision: 0.49073750436910174\n",
      "2024-11-25 20:45:06,075 - root - INFO - Recall: 0.5751741089717329\n",
      "2024-11-25 20:45:06,075 - root - INFO - Recall: 0.5751741089717329\n",
      "2024-11-25 20:45:06,075 - root - INFO - Recall: 0.5751741089717329\n",
      "2024-11-25 20:45:06,081 - root - INFO - F1 Score: 0.5296114673708034\n",
      "2024-11-25 20:45:06,081 - root - INFO - F1 Score: 0.5296114673708034\n",
      "2024-11-25 20:45:06,081 - root - INFO - F1 Score: 0.5296114673708034\n",
      "2024-11-25 20:45:06,090 - root - INFO - ROC AUC: 0.7564399340446334\n",
      "2024-11-25 20:45:06,090 - root - INFO - ROC AUC: 0.7564399340446334\n",
      "2024-11-25 20:45:06,090 - root - INFO - ROC AUC: 0.7564399340446334\n",
      "2024-11-25 20:45:06,097 - root - INFO - Confusion Matrix: \n",
      "[[21932  1457]\n",
      " [ 1037  1404]]\n",
      "2024-11-25 20:45:06,097 - root - INFO - Confusion Matrix: \n",
      "[[21932  1457]\n",
      " [ 1037  1404]]\n",
      "2024-11-25 20:45:06,097 - root - INFO - Confusion Matrix: \n",
      "[[21932  1457]\n",
      " [ 1037  1404]]\n",
      "2024-11-25 20:45:08,703 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:08,703 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:08,703 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:08,710 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,710 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,710 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,718 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,718 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,718 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,726 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:08,726 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:08,726 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:08,733 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:08,733 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:08,733 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:08,741 - root - INFO - ROC AUC: 0.7720956722391218\n",
      "2024-11-25 20:45:08,741 - root - INFO - ROC AUC: 0.7720956722391218\n",
      "2024-11-25 20:45:08,741 - root - INFO - ROC AUC: 0.7720956722391218\n",
      "2024-11-25 20:45:08,747 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n",
      "2024-11-25 20:45:08,747 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n",
      "2024-11-25 20:45:08,747 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n",
      "2024-11-25 20:45:08,978 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:08,978 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:08,978 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:08,986 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,986 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,986 - root - INFO - Accuracy: 0.9571815718157182\n",
      "2024-11-25 20:45:08,992 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,992 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,992 - root - INFO - Precision: 0.9992520568436799\n",
      "2024-11-25 20:45:08,997 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:08,997 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:08,997 - root - INFO - Recall: 0.5473166734944694\n",
      "2024-11-25 20:45:09,004 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:09,004 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:09,004 - root - INFO - F1 Score: 0.7072525145579672\n",
      "2024-11-25 20:45:09,010 - root - INFO - ROC AUC: 0.7809695885184598\n",
      "2024-11-25 20:45:09,010 - root - INFO - ROC AUC: 0.7809695885184598\n",
      "2024-11-25 20:45:09,010 - root - INFO - ROC AUC: 0.7809695885184598\n",
      "2024-11-25 20:45:09,017 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n",
      "2024-11-25 20:45:09,017 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n",
      "2024-11-25 20:45:09,017 - root - INFO - Confusion Matrix: \n",
      "[[23388     1]\n",
      " [ 1105  1336]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "{'accuracy': 0.6443670150987224, 'precision': np.float64(0.16945996275605213), 'recall': np.float64(0.7083162638263008), 'f1': np.float64(0.27348940208794686), 'roc_auc': np.float64(0.7594477170742543), 'confusion_matrix': array([[14915,  8474],\n",
      "       [  712,  1729]])}\n",
      "\n",
      "Decision Tree Evaluation:\n",
      "{'accuracy': 0.9034456058846303, 'precision': np.float64(0.49073750436910174), 'recall': np.float64(0.5751741089717329), 'f1': np.float64(0.5296114673708034), 'roc_auc': np.float64(0.7564399340446334), 'confusion_matrix': array([[21932,  1457],\n",
      "       [ 1037,  1404]])}\n",
      "\n",
      "Random Forest Evaluation:\n",
      "{'accuracy': 0.9571815718157182, 'precision': np.float64(0.9992520568436799), 'recall': np.float64(0.5473166734944694), 'f1': np.float64(0.7072525145579672), 'roc_auc': np.float64(0.7720956722391218), 'confusion_matrix': array([[23388,     1],\n",
      "       [ 1105,  1336]])}\n",
      "\n",
      "Gradient Boosting Evaluation:\n",
      "{'accuracy': 0.9571815718157182, 'precision': np.float64(0.9992520568436799), 'recall': np.float64(0.5473166734944694), 'f1': np.float64(0.7072525145579672), 'roc_auc': np.float64(0.7809695885184598), 'confusion_matrix': array([[23388,     1],\n",
      "       [ 1105,  1336]])}\n"
     ]
    }
   ],
   "source": [
    "# Extract the model objects from the training results\n",
    "logistic_model = logistic_results[\"model\"]\n",
    "decision_tree_model = decision_tree_results[\"model\"]\n",
    "random_forest_model = random_forest_results[\"model\"]\n",
    "gradient_boosting_model = gradient_boosting_results[\"model\"]\n",
    "\n",
    "# Evaluate each model\n",
    "logistic_evaluation = evaluate_model(logistic_model, X_test, y_test)\n",
    "decision_tree_evaluation = evaluate_model(decision_tree_model, X_test, y_test)\n",
    "random_forest_evaluation = evaluate_model(random_forest_model, X_test, y_test)\n",
    "gradient_boosting_evaluation = evaluate_model(gradient_boosting_model, X_test, y_test)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(logistic_evaluation)\n",
    "\n",
    "print(\"\\nDecision Tree Evaluation:\")\n",
    "print(decision_tree_evaluation)\n",
    "\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "print(random_forest_evaluation)\n",
    "\n",
    "print(\"\\nGradient Boosting Evaluation:\")\n",
    "print(gradient_boosting_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:45:09,188 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:09,188 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:09,188 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-25 20:45:09,195 - root - INFO - Accuracy: 0.9776019455115779\n",
      "2024-11-25 20:45:09,195 - root - INFO - Accuracy: 0.9776019455115779\n",
      "2024-11-25 20:45:09,195 - root - INFO - Accuracy: 0.9776019455115779\n",
      "2024-11-25 20:45:09,204 - root - INFO - Precision: 0.05965697240865026\n",
      "2024-11-25 20:45:09,204 - root - INFO - Precision: 0.05965697240865026\n",
      "2024-11-25 20:45:09,204 - root - INFO - Precision: 0.05965697240865026\n",
      "2024-11-25 20:45:09,214 - root - INFO - Recall: 0.8888888888888888\n",
      "2024-11-25 20:45:09,214 - root - INFO - Recall: 0.8888888888888888\n",
      "2024-11-25 20:45:09,214 - root - INFO - Recall: 0.8888888888888888\n",
      "2024-11-25 20:45:09,220 - root - INFO - F1 Score: 0.11180992313067785\n",
      "2024-11-25 20:45:09,220 - root - INFO - F1 Score: 0.11180992313067785\n",
      "2024-11-25 20:45:09,220 - root - INFO - F1 Score: 0.11180992313067785\n",
      "2024-11-25 20:45:09,228 - root - INFO - ROC AUC: 0.9754564584706141\n",
      "2024-11-25 20:45:09,228 - root - INFO - ROC AUC: 0.9754564584706141\n",
      "2024-11-25 20:45:09,228 - root - INFO - ROC AUC: 0.9754564584706141\n",
      "2024-11-25 20:45:09,236 - root - INFO - Confusion Matrix: \n",
      "[[55395  1261]\n",
      " [   10    80]]\n",
      "2024-11-25 20:45:09,236 - root - INFO - Confusion Matrix: \n",
      "[[55395  1261]\n",
      " [   10    80]]\n",
      "2024-11-25 20:45:09,236 - root - INFO - Confusion Matrix: \n",
      "[[55395  1261]\n",
      " [   10    80]]\n",
      "2024-11-25 20:45:09,348 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:09,348 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:09,348 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-25 20:45:09,354 - root - INFO - Accuracy: 0.999066013463504\n",
      "2024-11-25 20:45:09,354 - root - INFO - Accuracy: 0.999066013463504\n",
      "2024-11-25 20:45:09,354 - root - INFO - Accuracy: 0.999066013463504\n",
      "2024-11-25 20:45:09,359 - root - INFO - Precision: 0.6989247311827957\n",
      "2024-11-25 20:45:09,359 - root - INFO - Precision: 0.6989247311827957\n",
      "2024-11-25 20:45:09,359 - root - INFO - Precision: 0.6989247311827957\n",
      "2024-11-25 20:45:09,364 - root - INFO - Recall: 0.7222222222222222\n",
      "2024-11-25 20:45:09,364 - root - INFO - Recall: 0.7222222222222222\n",
      "2024-11-25 20:45:09,364 - root - INFO - Recall: 0.7222222222222222\n",
      "2024-11-25 20:45:09,373 - root - INFO - F1 Score: 0.7103825136612022\n",
      "2024-11-25 20:45:09,373 - root - INFO - F1 Score: 0.7103825136612022\n",
      "2024-11-25 20:45:09,373 - root - INFO - F1 Score: 0.7103825136612022\n",
      "2024-11-25 20:45:09,381 - root - INFO - ROC AUC: 0.8608640057736359\n",
      "2024-11-25 20:45:09,381 - root - INFO - ROC AUC: 0.8608640057736359\n",
      "2024-11-25 20:45:09,381 - root - INFO - ROC AUC: 0.8608640057736359\n",
      "2024-11-25 20:45:09,389 - root - INFO - Confusion Matrix: \n",
      "[[56628    28]\n",
      " [   25    65]]\n",
      "2024-11-25 20:45:09,389 - root - INFO - Confusion Matrix: \n",
      "[[56628    28]\n",
      " [   25    65]]\n",
      "2024-11-25 20:45:09,389 - root - INFO - Confusion Matrix: \n",
      "[[56628    28]\n",
      " [   25    65]]\n",
      "2024-11-25 20:45:10,842 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:10,842 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:10,842 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-25 20:45:10,848 - root - INFO - Accuracy: 0.9995241955380115\n",
      "2024-11-25 20:45:10,848 - root - INFO - Accuracy: 0.9995241955380115\n",
      "2024-11-25 20:45:10,848 - root - INFO - Accuracy: 0.9995241955380115\n",
      "2024-11-25 20:45:10,855 - root - INFO - Precision: 0.9846153846153847\n",
      "2024-11-25 20:45:10,855 - root - INFO - Precision: 0.9846153846153847\n",
      "2024-11-25 20:45:10,855 - root - INFO - Precision: 0.9846153846153847\n",
      "2024-11-25 20:45:10,861 - root - INFO - Recall: 0.7111111111111111\n",
      "2024-11-25 20:45:10,861 - root - INFO - Recall: 0.7111111111111111\n",
      "2024-11-25 20:45:10,861 - root - INFO - Recall: 0.7111111111111111\n",
      "2024-11-25 20:45:10,866 - root - INFO - F1 Score: 0.8258064516129032\n",
      "2024-11-25 20:45:10,866 - root - INFO - F1 Score: 0.8258064516129032\n",
      "2024-11-25 20:45:10,866 - root - INFO - F1 Score: 0.8258064516129032\n",
      "2024-11-25 20:45:10,874 - root - INFO - ROC AUC: 0.9369730380620666\n",
      "2024-11-25 20:45:10,874 - root - INFO - ROC AUC: 0.9369730380620666\n",
      "2024-11-25 20:45:10,874 - root - INFO - ROC AUC: 0.9369730380620666\n",
      "2024-11-25 20:45:10,880 - root - INFO - Confusion Matrix: \n",
      "[[56655     1]\n",
      " [   26    64]]\n",
      "2024-11-25 20:45:10,880 - root - INFO - Confusion Matrix: \n",
      "[[56655     1]\n",
      " [   26    64]]\n",
      "2024-11-25 20:45:10,880 - root - INFO - Confusion Matrix: \n",
      "[[56655     1]\n",
      " [   26    64]]\n",
      "2024-11-25 20:45:11,236 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:11,236 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:11,236 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-25 20:45:11,243 - root - INFO - Accuracy: 0.9993127268882388\n",
      "2024-11-25 20:45:11,243 - root - INFO - Accuracy: 0.9993127268882388\n",
      "2024-11-25 20:45:11,243 - root - INFO - Accuracy: 0.9993127268882388\n",
      "2024-11-25 20:45:11,248 - root - INFO - Precision: 0.9047619047619048\n",
      "2024-11-25 20:45:11,248 - root - INFO - Precision: 0.9047619047619048\n",
      "2024-11-25 20:45:11,248 - root - INFO - Precision: 0.9047619047619048\n",
      "2024-11-25 20:45:11,255 - root - INFO - Recall: 0.6333333333333333\n",
      "2024-11-25 20:45:11,255 - root - INFO - Recall: 0.6333333333333333\n",
      "2024-11-25 20:45:11,255 - root - INFO - Recall: 0.6333333333333333\n",
      "2024-11-25 20:45:11,260 - root - INFO - F1 Score: 0.7450980392156863\n",
      "2024-11-25 20:45:11,260 - root - INFO - F1 Score: 0.7450980392156863\n",
      "2024-11-25 20:45:11,260 - root - INFO - F1 Score: 0.7450980392156863\n",
      "2024-11-25 20:45:11,269 - root - INFO - ROC AUC: 0.7665101666195988\n",
      "2024-11-25 20:45:11,269 - root - INFO - ROC AUC: 0.7665101666195988\n",
      "2024-11-25 20:45:11,269 - root - INFO - ROC AUC: 0.7665101666195988\n",
      "2024-11-25 20:45:11,275 - root - INFO - Confusion Matrix: \n",
      "[[56650     6]\n",
      " [   33    57]]\n",
      "2024-11-25 20:45:11,275 - root - INFO - Confusion Matrix: \n",
      "[[56650     6]\n",
      " [   33    57]]\n",
      "2024-11-25 20:45:11,275 - root - INFO - Confusion Matrix: \n",
      "[[56650     6]\n",
      " [   33    57]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation (Credit Card Fraud):\n",
      "{'accuracy': 0.9776019455115779, 'precision': np.float64(0.05965697240865026), 'recall': np.float64(0.8888888888888888), 'f1': np.float64(0.11180992313067785), 'roc_auc': np.float64(0.9754564584706141), 'confusion_matrix': array([[55395,  1261],\n",
      "       [   10,    80]])}\n",
      "\n",
      "Decision Tree Evaluation (Credit Card Fraud):\n",
      "{'accuracy': 0.999066013463504, 'precision': np.float64(0.6989247311827957), 'recall': np.float64(0.7222222222222222), 'f1': np.float64(0.7103825136612022), 'roc_auc': np.float64(0.8608640057736359), 'confusion_matrix': array([[56628,    28],\n",
      "       [   25,    65]])}\n",
      "\n",
      "Random Forest Evaluation (Credit Card Fraud):\n",
      "{'accuracy': 0.9995241955380115, 'precision': np.float64(0.9846153846153847), 'recall': np.float64(0.7111111111111111), 'f1': np.float64(0.8258064516129032), 'roc_auc': np.float64(0.9369730380620666), 'confusion_matrix': array([[56655,     1],\n",
      "       [   26,    64]])}\n",
      "\n",
      "Gradient Boosting Evaluation (Credit Card Fraud):\n",
      "{'accuracy': 0.9993127268882388, 'precision': np.float64(0.9047619047619048), 'recall': np.float64(0.6333333333333333), 'f1': np.float64(0.7450980392156863), 'roc_auc': np.float64(0.7665101666195988), 'confusion_matrix': array([[56650,     6],\n",
      "       [   33,    57]])}\n"
     ]
    }
   ],
   "source": [
    "# Extract the model objects from the training results for credit card fraud detection\n",
    "credit_logistic_model = credit_logistic_results[\"model\"]\n",
    "credit_decision_tree_model = credit_decision_tree_results[\"model\"]\n",
    "credit_random_forest_model = credit_random_forest_results[\"model\"]\n",
    "credit_gradient_boosting_model = credit_gradient_boosting_results[\"model\"]\n",
    "\n",
    "# Evaluate each credit card fraud detection model\n",
    "credit_logistic_evaluation = evaluate_model(credit_logistic_model, X_test_credit, y_test_credit)\n",
    "credit_decision_tree_evaluation = evaluate_model(credit_decision_tree_model, X_test_credit, y_test_credit)\n",
    "credit_random_forest_evaluation = evaluate_model(credit_random_forest_model, X_test_credit, y_test_credit)\n",
    "credit_gradient_boosting_evaluation = evaluate_model(credit_gradient_boosting_model, X_test_credit, y_test_credit)\n",
    "\n",
    "# Display evaluation results for credit card fraud detection models\n",
    "print(\"Logistic Regression Evaluation (Credit Card Fraud):\")\n",
    "print(credit_logistic_evaluation)\n",
    "\n",
    "print(\"\\nDecision Tree Evaluation (Credit Card Fraud):\")\n",
    "print(credit_decision_tree_evaluation)\n",
    "\n",
    "print(\"\\nRandom Forest Evaluation (Credit Card Fraud):\")\n",
    "print(credit_random_forest_evaluation)\n",
    "\n",
    "print(\"\\nGradient Boosting Evaluation (Credit Card Fraud):\")\n",
    "print(credit_gradient_boosting_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 20:45:11,314 - root - INFO - Starting explanation for model type: lr.\n",
      "2024-11-25 20:45:11,314 - root - INFO - Starting explanation for model type: lr.\n",
      "2024-11-25 20:45:11,314 - root - INFO - Starting explanation for model type: lr.\n",
      "2024-11-25 20:45:11,416 - shap - WARNING - Using 103316 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "2024-11-25 20:45:11,416 - shap - WARNING - Using 103316 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "2024-11-25 20:45:11,416 - shap - WARNING - Using 103316 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "2024-11-25 20:45:11,425 - root - INFO - Using KernelExplainer for Logistic Regression model.\n",
      "2024-11-25 20:45:11,425 - root - INFO - Using KernelExplainer for Logistic Regression model.\n",
      "2024-11-25 20:45:11,425 - root - INFO - Using KernelExplainer for Logistic Regression model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining Logistic Regression Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103316 [01:19<?, ?it/s]\n",
      "2024-11-25 20:46:31,317 - root - ERROR - Error in explaining model: Unable to allocate 25.6 GiB for an array with shape (2076, 1653056) and data type float64\n",
      "2024-11-25 20:46:31,317 - root - ERROR - Error in explaining model: Unable to allocate 25.6 GiB for an array with shape (2076, 1653056) and data type float64\n",
      "2024-11-25 20:46:31,317 - root - ERROR - Error in explaining model: Unable to allocate 25.6 GiB for an array with shape (2076, 1653056) and data type float64\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 25.6 GiB for an array with shape (2076, 1653056) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplaining Logistic Regression Model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SHAP explanation for Logistic Regression\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m logistic_shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplain_model_shap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogistic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# LIME explanation for Logistic Regression\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLIME explanation for Logistic Regression:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\notebooks\\../fraud_detection\\model_explainability.py:31\u001b[0m, in \u001b[0;36mexplain_model_shap\u001b[1;34m(model, X_train, X_test, model_type)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Generate SHAP values for the training dataset\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHAP values computed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Visualize SHAP plots (these will show up interactively)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\myvenv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:271\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[0;32m    270\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[1;32m--> 271\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    273\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mc:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\myvenv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:362\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[1;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# reserve space for some of our computations\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallocate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# weight the different subset sizes\u001b[39;00m\n\u001b[0;32m    365\u001b[0m num_subset_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\myvenv\\Lib\\site-packages\\shap\\explainers\\_kernel.py:567\u001b[0m, in \u001b[0;36mKernelExplainer.allocate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynth_data \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix((new_data, new_indices, new_indptr), shape\u001b[38;5;241m=\u001b[39mshape)\u001b[38;5;241m.\u001b[39mtolil()\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynth_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaskMatrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM))\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernelWeights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsamples)\n",
      "File \u001b[1;32mc:\\Users\\Yonas\\Desktop\\proj\\yonasKu-fraud-detection-for-e-commerce-and-bank-transactions\\myvenv\\Lib\\site-packages\\numpy\\lib\\_shape_base_impl.py:1284\u001b[0m, in \u001b[0;36mtile\u001b[1;34m(A, reps)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dim_in, nrep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(c\u001b[38;5;241m.\u001b[39mshape, tup):\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m nrep \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1284\u001b[0m             c \u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m         n \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m dim_in\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39mreshape(shape_out)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 25.6 GiB for an array with shape (2076, 1653056) and data type float64"
     ]
    }
   ],
   "source": [
    "# Explaining Logistic Regression Model\n",
    "print(\"Explaining Logistic Regression Model:\")\n",
    "\n",
    "# SHAP explanation for Logistic Regression\n",
    "logistic_shap_values = explain_model_shap(logistic_model, X_train, X_test, model_type='lr')\n",
    "\n",
    "# LIME explanation for Logistic Regression\n",
    "print(\"LIME explanation for Logistic Regression:\")\n",
    "explanation_lime_lr = explain_model_lime(logistic_model, X_train, X_test, idx=0)\n",
    "\n",
    "\n",
    "# Explaining Decision Tree Model\n",
    "print(\"Explaining Decision Tree Model:\")\n",
    "\n",
    "# SHAP explanation for Decision Tree\n",
    "decision_tree_shap_values = explain_model_shap(decision_tree_model, X_train, X_test, model_type='rf')\n",
    "\n",
    "# LIME explanation for Decision Tree\n",
    "print(\"LIME explanation for Decision Tree:\")\n",
    "explanation_lime_dt = explain_model_lime(decision_tree_model, X_train, X_test, idx=0)\n",
    "\n",
    "\n",
    "# Explaining Random Forest Model\n",
    "print(\"Explaining Random Forest Model:\")\n",
    "\n",
    "# SHAP explanation for Random Forest\n",
    "random_forest_shap_values = explain_model_shap(random_forest_model, X_train, X_test, model_type='rf')\n",
    "\n",
    "# LIME explanation for Random Forest\n",
    "print(\"LIME explanation for Random Forest:\")\n",
    "explanation_lime_rf = explain_model_lime(random_forest_model, X_train, X_test, idx=0)\n",
    "\n",
    "\n",
    "# Explaining Gradient Boosting Model\n",
    "print(\"Explaining Gradient Boosting Model:\")\n",
    "\n",
    "# SHAP explanation for Gradient Boosting\n",
    "gradient_boosting_shap_values = explain_model_shap(gradient_boosting_model, X_train, X_test, model_type='rf')\n",
    "\n",
    "# LIME explanation for Gradient Boosting\n",
    "print(\"LIME explanation for Gradient Boosting:\")\n",
    "explanation_lime_gb = explain_model_lime(gradient_boosting_model, X_train, X_test, idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)  # Output will be in the form (num_samples, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining Logistic Regression Model (Credit Card Fraud)\n",
    "print(\"Explaining Logistic Regression Model (Credit Card Fraud):\")\n",
    "\n",
    "# SHAP explanation for Logistic Regression\n",
    "credit_logistic_shap_values = explain_model_shap(\n",
    "    credit_logistic_model, X_train_credit, X_test_credit, model_type='lr'\n",
    ")\n",
    "\n",
    "# LIME explanation for Logistic Regression\n",
    "print(\"LIME Explanation for Logistic Regression (Credit Card Fraud):\")\n",
    "credit_explanation_lime_lr = explain_model_lime(\n",
    "    credit_logistic_model, X_train_credit, X_test_credit, idx=0\n",
    ")\n",
    "\n",
    "\n",
    "# Explaining Decision Tree Model (Credit Card Fraud)\n",
    "print(\"Explaining Decision Tree Model (Credit Card Fraud):\")\n",
    "\n",
    "# SHAP explanation for Decision Tree\n",
    "credit_decision_tree_shap_values = explain_model_shap(\n",
    "    credit_decision_tree_model, X_train_credit, X_test_credit, model_type='rf'\n",
    ")\n",
    "\n",
    "# LIME explanation for Decision Tree\n",
    "print(\"LIME Explanation for Decision Tree (Credit Card Fraud):\")\n",
    "credit_explanation_lime_dt = explain_model_lime(\n",
    "    credit_decision_tree_model, X_train_credit, X_test_credit, idx=0\n",
    ")\n",
    "\n",
    "\n",
    "# Explaining Random Forest Model (Credit Card Fraud)\n",
    "print(\"Explaining Random Forest Model (Credit Card Fraud):\")\n",
    "\n",
    "# SHAP explanation for Random Forest\n",
    "credit_random_forest_shap_values = explain_model_shap(\n",
    "    credit_random_forest_model, X_train_credit, X_test_credit, model_type='rf'\n",
    ")\n",
    "\n",
    "# LIME explanation for Random Forest\n",
    "print(\"LIME Explanation for Random Forest (Credit Card Fraud):\")\n",
    "credit_explanation_lime_rf = explain_model_lime(\n",
    "    credit_random_forest_model, X_train_credit, X_test_credit, idx=0\n",
    ")\n",
    "\n",
    "\n",
    "# Explaining Gradient Boosting Model (Credit Card Fraud)\n",
    "print(\"Explaining Gradient Boosting Model (Credit Card Fraud):\")\n",
    "\n",
    "# SHAP explanation for Gradient Boosting\n",
    "credit_gradient_boosting_shap_values = explain_model_shap(\n",
    "    credit_gradient_boosting_model, X_train_credit, X_test_credit, model_type='rf'\n",
    ")\n",
    "\n",
    "# LIME explanation for Gradient Boosting\n",
    "print(\"LIME Explanation for Gradient Boosting (Credit Card Fraud):\")\n",
    "credit_explanation_lime_gb = explain_model_lime(\n",
    "    credit_gradient_boosting_model, X_train_credit, X_test_credit, idx=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define file paths for saving models\n",
    "# mlp_model_path = '../models/mlp_model.h5'\n",
    "# rnn_model_path = '../models/rnn_model.h5'\n",
    "# cnn_model_path = '../models/cnn_model.h5'\n",
    "# lstm_model_path = '../models/lstm_model.h5'\n",
    "\n",
    "# # Train and save the MLP model\n",
    "# print(\"Training MLP model...\")\n",
    "# mlp_model, mlp_history = train_mlp(X_train, X_test, y_train, y_test, mlp_model_path)\n",
    "# print(\"\\nMLP Model Training History:\")\n",
    "# print(mlp_history)\n",
    "\n",
    "\n",
    "\n",
    "# # Train and save the LSTM model\n",
    "# print(\"\\nTraining LSTM model...\")\n",
    "# lstm_model, lstm_history = train_lstm(X_train, X_test, y_train, y_test, lstm_model_path)\n",
    "# print(\"\\nLSTM Model Training History:\")\n",
    "# print(lstm_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and save the CNN model\n",
    "# print(\"\\nTraining CNN model...\")\n",
    "# cnn_model, cnn_history = train_cnn(X_train, X_test, y_train, y_test, cnn_model_path)\n",
    "# print(\"\\nCNN Model Training History:\")\n",
    "# print(cnn_history)\n",
    "\n",
    "# # Train and save the RNN model\n",
    "# print(\"\\nTraining RNN model...\")\n",
    "# rnn_model, rnn_history = train_rnn(X_train, X_test, y_train, y_test, rnn_model_path)\n",
    "# print(\"\\nRNN Model Training History:\")\n",
    "# print(rnn_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the MLP, RNN, and LSTM models\n",
    "# mlp_evaluation = evaluate_model(mlp_model, X_test, y_test)\n",
    "# rnn_evaluation = evaluate_model(rnn_model, X_test, y_test)\n",
    "# lstm_evaluation = evaluate_model(lstm_model, X_test, y_test)\n",
    "\n",
    "# # Display evaluation results\n",
    "# print(\"\\nMLP Model Evaluation:\")\n",
    "# print(mlp_evaluation)\n",
    "\n",
    "# print(\"\\nRNN Model Evaluation:\")\n",
    "# print(rnn_evaluation)\n",
    "\n",
    "# print(\"\\nLSTM Model Evaluation:\")\n",
    "# print(lstm_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Paths to the saved models\n",
    "# mlp_model_path = '../models/mlp_model.h5'\n",
    "# rnn_model_path = '../models/rnn_model.h5'\n",
    "# cnn_model_path = '../models/cnn_model.h5'\n",
    "# lstm_model_path = '../models/lstm_model.h5'\n",
    "\n",
    "# # Load the saved models\n",
    "# mlp_model = load_model(mlp_model_path)\n",
    "# rnn_model = load_model(rnn_model_path)\n",
    "# cnn_model = load_model(cnn_model_path)\n",
    "# lstm_model = load_model(lstm_model_path)\n",
    "\n",
    "# # Test the models and evaluate them\n",
    "# print(\"Evaluating MLP model...\")\n",
    "# mlp_evaluation = evaluate_model(mlp_model, X_test, y_test)\n",
    "# print(\"MLP Model Evaluation:\", mlp_evaluation)\n",
    "\n",
    "# print(\"\\nEvaluating RNN model...\")\n",
    "# rnn_evaluation = evaluate_model(rnn_model, X_test, y_test)\n",
    "# print(\"RNN Model Evaluation:\", rnn_evaluation)\n",
    "\n",
    "# print(\"\\nEvaluating CNN model...\")\n",
    "# cnn_evaluation = evaluate_model(cnn_model, X_test, y_test)\n",
    "# print(\"CNN Model Evaluation:\", cnn_evaluation)\n",
    "\n",
    "# print(\"\\nEvaluating LSTM model...\")\n",
    "# lstm_evaluation = evaluate_model(lstm_model, X_test, y_test)\n",
    "# print(\"LSTM Model Evaluation:\", lstm_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
