{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# notebooks/eda_fraud_detection.ipynb\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Import the necessary functions from your project\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# from model_training import prepare_data, train_logistic_regression , train_random_forest , train_gradient_boosting ,train_decision_tree,  train_mlp,train_rnn,train_cnn,train_lstm\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_training\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (prepare_data, train_logistic_regression, train_random_forest, \n\u001b[0;32m     11\u001b[0m                             train_gradient_boosting, train_decision_tree, )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_evaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_model\n",
      "File \u001b[1;32mc:\\Users\\Akram 1\\Desktop\\New folder (2)\\fraud-detection-for-e-commercand-bank-transactions\\notebooks\\../fraud_detection\\model_training.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, LabelEncoder\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, LSTM, SimpleRNN, Conv1D, MaxPooling1D, Flatten\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import sys\n",
    "sys.path.append('../fraud_detection')  # Adjust this path based on your working directory\n",
    "from utils.logging_util import setup_logger\n",
    "\n",
    "# notebooks/eda_fraud_detection.ipynb\n",
    "\n",
    "# Import the necessary functions from your project\n",
    "# from model_training import prepare_data, train_logistic_regression , train_random_forest , train_gradient_boosting ,train_decision_tree,  train_mlp,train_rnn,train_cnn,train_lstm\n",
    "from model_training import (prepare_data, train_logistic_regression, train_random_forest, \n",
    "                            train_gradient_boosting, train_decision_tree, )\n",
    "\n",
    "from model_evaluation import evaluate_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/fraud_datas.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m prepared_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m(data_path, target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfraud_class\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prepare_data' is not defined"
     ]
    }
   ],
   "source": [
    "data_path = '../data/fraud_datas.csv'\n",
    "prepared_data = prepare_data(data_path, target_column='fraud_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Access the prepared data\n",
    "X_train = prepared_data['X_train']\n",
    "X_test = prepared_data['X_test']\n",
    "y_train = prepared_data['y_train']\n",
    "y_test = prepared_data['y_test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 09:11:24,561 - root - INFO - Training model: LogisticRegression.\n",
      "2024-11-16 09:11:24,561 - root - INFO - Training model: LogisticRegression.\n",
      "2024-11-16 09:11:24,786 - root - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-16 09:11:24,786 - root - INFO - Model saved to ../models/logistic_regression_model.pkl.\n",
      "2024-11-16 09:11:24,833 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:11:24,833 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:11:24,833 - root - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-16 09:11:24,833 - root - INFO - Training model: RandomForestClassifier.\n",
      "2024-11-16 09:12:27,618 - root - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-16 09:12:27,618 - root - INFO - Model saved to ../models/random_forest_model.pkl.\n",
      "2024-11-16 09:12:29,391 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:12:29,391 - root - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': LogisticRegression(class_weight='balanced', max_iter=2000), 'training_time': 0.20903968811035156, 'roc_auc': np.float64(0.7580767576706717), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.64      0.77     27373\\n           1       0.17      0.70      0.27      2850\\n\\n    accuracy                           0.65     30223\\n   macro avg       0.56      0.67      0.52     30223\\nweighted avg       0.88      0.65      0.72     30223\\n'}\n",
      "{'model': RandomForestClassifier(class_weight='balanced'), 'training_time': 62.637763261795044, 'roc_auc': np.float64(0.7693871345883797), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.98     27373\\n           1       1.00      0.54      0.70      2850\\n\\n    accuracy                           0.96     30223\\n   macro avg       0.98      0.77      0.84     30223\\nweighted avg       0.96      0.96      0.95     30223\\n'}\n"
     ]
    }
   ],
   "source": [
    "# Train and save the Logistic Regression model\n",
    "logistic_model_path = '../models/logistic_regression_model.pkl'\n",
    "logistic_results = train_logistic_regression(X_train, X_test, y_train, y_test, logistic_model_path)\n",
    "\n",
    "# Train and save the Random Forest model\n",
    "random_forest_model_path = '../models/random_forest_model.pkl'\n",
    "random_forest_results = train_random_forest(X_train, X_test, y_train, y_test, random_forest_model_path)\n",
    "\n",
    "# Display results\n",
    "print(logistic_results)\n",
    "print(random_forest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 09:42:03,874 - root - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-16 09:42:03,874 - root - INFO - Training model: DecisionTreeClassifier.\n",
      "2024-11-16 09:42:08,093 - root - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-16 09:42:08,093 - root - INFO - Model saved to ../models/decision_tree_model.pkl.\n",
      "2024-11-16 09:42:08,164 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:42:08,164 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:42:08,167 - root - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-16 09:42:08,167 - root - INFO - Training model: GradientBoostingClassifier.\n",
      "2024-11-16 09:43:07,796 - root - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-16 09:43:07,796 - root - INFO - Model saved to ../models/gradient_boosting_model.pkl.\n",
      "2024-11-16 09:43:07,925 - root - INFO - Model training and evaluation completed successfully.\n",
      "2024-11-16 09:43:07,925 - root - INFO - Model training and evaluation completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Model Results:\n",
      "{'model': DecisionTreeClassifier(), 'training_time': 4.2173683643341064, 'roc_auc': np.float64(0.754724683883017), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      0.94      0.95     27373\\n           1       0.51      0.57      0.54      2850\\n\\n    accuracy                           0.91     30223\\n   macro avg       0.73      0.75      0.74     30223\\nweighted avg       0.91      0.91      0.91     30223\\n'}\n",
      "\n",
      "Gradient Boosting Model Results:\n",
      "{'model': GradientBoostingClassifier(), 'training_time': 59.62649416923523, 'roc_auc': np.float64(0.7743317752606775), 'report': '              precision    recall  f1-score   support\\n\\n           0       0.95      1.00      0.98     27373\\n           1       1.00      0.54      0.70      2850\\n\\n    accuracy                           0.96     30223\\n   macro avg       0.98      0.77      0.84     30223\\nweighted avg       0.96      0.96      0.95     30223\\n'}\n"
     ]
    }
   ],
   "source": [
    "# # Import necessary functions\n",
    "# from fraud_detection.model_training import train_logistic_regression, train_decision_tree, train_random_forest, train_gradient_boosting\n",
    "\n",
    "\n",
    "decision_tree_model_path = '../models/decision_tree_model.pkl'\n",
    "\n",
    "gradient_boosting_model_path = '../models/gradient_boosting_model.pkl'\n",
    "\n",
    "\n",
    "# Train and save the Decision Tree model\n",
    "decision_tree_results = train_decision_tree(X_train, X_test, y_train, y_test, decision_tree_model_path)\n",
    "\n",
    "\n",
    "# Train and save the Gradient Boosting model\n",
    "gradient_boosting_results = train_gradient_boosting(X_train, X_test, y_train, y_test, gradient_boosting_model_path)\n",
    "\n",
    "# Display results for all models\n",
    "\n",
    "print(\"\\nDecision Tree Model Results:\")\n",
    "print(decision_tree_results)\n",
    "\n",
    "print(\"\\nGradient Boosting Model Results:\")\n",
    "print(gradient_boosting_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 09:14:35,246 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-16 09:14:35,246 - root - INFO - Evaluation metrics for LogisticRegression:\n",
      "2024-11-16 09:14:35,248 - root - INFO - Accuracy: 0.6482480230288191\n",
      "2024-11-16 09:14:35,248 - root - INFO - Accuracy: 0.6482480230288191\n",
      "2024-11-16 09:14:35,249 - root - INFO - Precision: 0.16937197246536925\n",
      "2024-11-16 09:14:35,249 - root - INFO - Precision: 0.16937197246536925\n",
      "2024-11-16 09:14:35,250 - root - INFO - Recall: 0.6992982456140351\n",
      "2024-11-16 09:14:35,250 - root - INFO - Recall: 0.6992982456140351\n",
      "2024-11-16 09:14:35,253 - root - INFO - F1 Score: 0.27269617568584525\n",
      "2024-11-16 09:14:35,253 - root - INFO - F1 Score: 0.27269617568584525\n",
      "2024-11-16 09:14:35,255 - root - INFO - ROC AUC: 0.7580767576706717\n",
      "2024-11-16 09:14:35,255 - root - INFO - ROC AUC: 0.7580767576706717\n",
      "2024-11-16 09:14:35,259 - root - INFO - Confusion Matrix: \n",
      "[[17599  9774]\n",
      " [  857  1993]]\n",
      "2024-11-16 09:14:35,259 - root - INFO - Confusion Matrix: \n",
      "[[17599  9774]\n",
      " [  857  1993]]\n",
      "2024-11-16 09:14:35,326 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-16 09:14:35,326 - root - INFO - Evaluation metrics for DecisionTreeClassifier:\n",
      "2024-11-16 09:14:35,328 - root - INFO - Accuracy: 0.9067928398901499\n",
      "2024-11-16 09:14:35,328 - root - INFO - Accuracy: 0.9067928398901499\n",
      "2024-11-16 09:14:35,330 - root - INFO - Precision: 0.5052001260636622\n",
      "2024-11-16 09:14:35,330 - root - INFO - Precision: 0.5052001260636622\n",
      "2024-11-16 09:14:35,331 - root - INFO - Recall: 0.5624561403508772\n",
      "2024-11-16 09:14:35,331 - root - INFO - Recall: 0.5624561403508772\n",
      "2024-11-16 09:14:35,333 - root - INFO - F1 Score: 0.5322928773036693\n",
      "2024-11-16 09:14:35,333 - root - INFO - F1 Score: 0.5322928773036693\n",
      "2024-11-16 09:14:35,336 - root - INFO - ROC AUC: 0.7525501759000577\n",
      "2024-11-16 09:14:35,336 - root - INFO - ROC AUC: 0.7525501759000577\n",
      "2024-11-16 09:14:35,338 - root - INFO - Confusion Matrix: \n",
      "[[25803  1570]\n",
      " [ 1247  1603]]\n",
      "2024-11-16 09:14:35,338 - root - INFO - Confusion Matrix: \n",
      "[[25803  1570]\n",
      " [ 1247  1603]]\n",
      "2024-11-16 09:14:37,010 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-16 09:14:37,010 - root - INFO - Evaluation metrics for RandomForestClassifier:\n",
      "2024-11-16 09:14:37,010 - root - INFO - Accuracy: 0.956390828177216\n",
      "2024-11-16 09:14:37,010 - root - INFO - Accuracy: 0.956390828177216\n",
      "2024-11-16 09:14:37,010 - root - INFO - Precision: 0.999348109517601\n",
      "2024-11-16 09:14:37,010 - root - INFO - Precision: 0.999348109517601\n",
      "2024-11-16 09:14:37,026 - root - INFO - Recall: 0.5378947368421053\n",
      "2024-11-16 09:14:37,026 - root - INFO - Recall: 0.5378947368421053\n",
      "2024-11-16 09:14:37,026 - root - INFO - F1 Score: 0.6993613138686131\n",
      "2024-11-16 09:14:37,026 - root - INFO - F1 Score: 0.6993613138686131\n",
      "2024-11-16 09:14:37,026 - root - INFO - ROC AUC: 0.7693871345883797\n",
      "2024-11-16 09:14:37,026 - root - INFO - ROC AUC: 0.7693871345883797\n",
      "2024-11-16 09:14:37,026 - root - INFO - Confusion Matrix: \n",
      "[[27372     1]\n",
      " [ 1317  1533]]\n",
      "2024-11-16 09:14:37,026 - root - INFO - Confusion Matrix: \n",
      "[[27372     1]\n",
      " [ 1317  1533]]\n",
      "2024-11-16 09:14:37,211 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-16 09:14:37,211 - root - INFO - Evaluation metrics for GradientBoostingClassifier:\n",
      "2024-11-16 09:14:37,211 - root - INFO - Accuracy: 0.9564239155609966\n",
      "2024-11-16 09:14:37,211 - root - INFO - Accuracy: 0.9564239155609966\n",
      "2024-11-16 09:14:37,211 - root - INFO - Precision: 1.0\n",
      "2024-11-16 09:14:37,211 - root - INFO - Precision: 1.0\n",
      "2024-11-16 09:14:37,211 - root - INFO - Recall: 0.5378947368421053\n",
      "2024-11-16 09:14:37,211 - root - INFO - Recall: 0.5378947368421053\n",
      "2024-11-16 09:14:37,211 - root - INFO - F1 Score: 0.6995208761122519\n",
      "2024-11-16 09:14:37,211 - root - INFO - F1 Score: 0.6995208761122519\n",
      "2024-11-16 09:14:37,211 - root - INFO - ROC AUC: 0.7743449397248281\n",
      "2024-11-16 09:14:37,211 - root - INFO - ROC AUC: 0.7743449397248281\n",
      "2024-11-16 09:14:37,211 - root - INFO - Confusion Matrix: \n",
      "[[27373     0]\n",
      " [ 1317  1533]]\n",
      "2024-11-16 09:14:37,211 - root - INFO - Confusion Matrix: \n",
      "[[27373     0]\n",
      " [ 1317  1533]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Evaluation:\n",
      "{'accuracy': 0.6482480230288191, 'precision': np.float64(0.16937197246536925), 'recall': np.float64(0.6992982456140351), 'f1': np.float64(0.27269617568584525), 'roc_auc': np.float64(0.7580767576706717), 'confusion_matrix': array([[17599,  9774],\n",
      "       [  857,  1993]])}\n",
      "\n",
      "Decision Tree Evaluation:\n",
      "{'accuracy': 0.9067928398901499, 'precision': np.float64(0.5052001260636622), 'recall': np.float64(0.5624561403508772), 'f1': np.float64(0.5322928773036693), 'roc_auc': np.float64(0.7525501759000577), 'confusion_matrix': array([[25803,  1570],\n",
      "       [ 1247,  1603]])}\n",
      "\n",
      "Random Forest Evaluation:\n",
      "{'accuracy': 0.956390828177216, 'precision': np.float64(0.999348109517601), 'recall': np.float64(0.5378947368421053), 'f1': np.float64(0.6993613138686131), 'roc_auc': np.float64(0.7693871345883797), 'confusion_matrix': array([[27372,     1],\n",
      "       [ 1317,  1533]])}\n",
      "\n",
      "Gradient Boosting Evaluation:\n",
      "{'accuracy': 0.9564239155609966, 'precision': np.float64(1.0), 'recall': np.float64(0.5378947368421053), 'f1': np.float64(0.6995208761122519), 'roc_auc': np.float64(0.7743449397248281), 'confusion_matrix': array([[27373,     0],\n",
      "       [ 1317,  1533]])}\n"
     ]
    }
   ],
   "source": [
    "# Extract the model objects from the training results\n",
    "logistic_model = logistic_results[\"model\"]\n",
    "decision_tree_model = decision_tree_results[\"model\"]\n",
    "random_forest_model = random_forest_results[\"model\"]\n",
    "gradient_boosting_model = gradient_boosting_results[\"model\"]\n",
    "\n",
    "# Evaluate each model\n",
    "logistic_evaluation = evaluate_model(logistic_model, X_test, y_test)\n",
    "decision_tree_evaluation = evaluate_model(decision_tree_model, X_test, y_test)\n",
    "random_forest_evaluation = evaluate_model(random_forest_model, X_test, y_test)\n",
    "gradient_boosting_evaluation = evaluate_model(gradient_boosting_model, X_test, y_test)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"Logistic Regression Evaluation:\")\n",
    "print(logistic_evaluation)\n",
    "\n",
    "print(\"\\nDecision Tree Evaluation:\")\n",
    "print(decision_tree_evaluation)\n",
    "\n",
    "print(\"\\nRandom Forest Evaluation:\")\n",
    "print(random_forest_evaluation)\n",
    "\n",
    "print(\"\\nGradient Boosting Evaluation:\")\n",
    "print(gradient_boosting_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train and save the MLP model\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining MLP model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m mlp_model, mlp_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mlp\u001b[49m(X_train, X_test, y_train, y_test, mlp_model_path)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMLP Model Training History:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(mlp_history)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_mlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file paths for saving models\n",
    "mlp_model_path = '../models/mlp_model.h5'\n",
    "rnn_model_path = '../models/rnn_model.h5'\n",
    "cnn_model_path = '../models/cnn_model.h5'\n",
    "lstm_model_path = '../models/lstm_model.h5'\n",
    "\n",
    "# Train and save the MLP model\n",
    "print(\"Training MLP model...\")\n",
    "mlp_model, mlp_history = train_mlp(X_train, X_test, y_train, y_test, mlp_model_path)\n",
    "print(\"\\nMLP Model Training History:\")\n",
    "print(mlp_history)\n",
    "\n",
    "\n",
    "\n",
    "# Train and save the LSTM model\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "lstm_model, lstm_history = train_lstm(X_train, X_test, y_train, y_test, lstm_model_path)\n",
    "print(\"\\nLSTM Model Training History:\")\n",
    "print(lstm_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save the CNN model\n",
    "print(\"\\nTraining CNN model...\")\n",
    "cnn_model, cnn_history = train_cnn(X_train, X_test, y_train, y_test, cnn_model_path)\n",
    "print(\"\\nCNN Model Training History:\")\n",
    "print(cnn_history)\n",
    "\n",
    "# Train and save the RNN model\n",
    "print(\"\\nTraining RNN model...\")\n",
    "rnn_model, rnn_history = train_rnn(X_train, X_test, y_train, y_test, rnn_model_path)\n",
    "print(\"\\nRNN Model Training History:\")\n",
    "print(rnn_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the MLP, RNN, and LSTM models\n",
    "mlp_evaluation = evaluate_model(mlp_model, X_test, y_test)\n",
    "rnn_evaluation = evaluate_model(rnn_model, X_test, y_test)\n",
    "lstm_evaluation = evaluate_model(lstm_model, X_test, y_test)\n",
    "\n",
    "# Display evaluation results\n",
    "print(\"\\nMLP Model Evaluation:\")\n",
    "print(mlp_evaluation)\n",
    "\n",
    "print(\"\\nRNN Model Evaluation:\")\n",
    "print(rnn_evaluation)\n",
    "\n",
    "print(\"\\nLSTM Model Evaluation:\")\n",
    "print(lstm_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the saved models\n",
    "mlp_model_path = '../models/mlp_model.h5'\n",
    "rnn_model_path = '../models/rnn_model.h5'\n",
    "cnn_model_path = '../models/cnn_model.h5'\n",
    "lstm_model_path = '../models/lstm_model.h5'\n",
    "\n",
    "# Load the saved models\n",
    "mlp_model = load_model(mlp_model_path)\n",
    "rnn_model = load_model(rnn_model_path)\n",
    "cnn_model = load_model(cnn_model_path)\n",
    "lstm_model = load_model(lstm_model_path)\n",
    "\n",
    "# Test the models and evaluate them\n",
    "print(\"Evaluating MLP model...\")\n",
    "mlp_evaluation = evaluate_model(mlp_model, X_test, y_test)\n",
    "print(\"MLP Model Evaluation:\", mlp_evaluation)\n",
    "\n",
    "print(\"\\nEvaluating RNN model...\")\n",
    "rnn_evaluation = evaluate_model(rnn_model, X_test, y_test)\n",
    "print(\"RNN Model Evaluation:\", rnn_evaluation)\n",
    "\n",
    "print(\"\\nEvaluating CNN model...\")\n",
    "cnn_evaluation = evaluate_model(cnn_model, X_test, y_test)\n",
    "print(\"CNN Model Evaluation:\", cnn_evaluation)\n",
    "\n",
    "print(\"\\nEvaluating LSTM model...\")\n",
    "lstm_evaluation = evaluate_model(lstm_model, X_test, y_test)\n",
    "print(\"LSTM Model Evaluation:\", lstm_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
